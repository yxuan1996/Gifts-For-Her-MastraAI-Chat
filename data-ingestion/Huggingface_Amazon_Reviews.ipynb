{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Huggingface Amazon Reviews Dataset\n",
        "\n",
        "https://huggingface.co/datasets/McAuley-Lab/Amazon-Reviews-2023\n",
        "\n",
        "https://amazon-reviews-2023.github.io/\n",
        "\n",
        "\n",
        "Note: Huggingface loading is not supported, we will use curl to download manually\n",
        "\n",
        "We will download datasets in the beauty / personal care category"
      ],
      "metadata": {
        "id": "MXIST2iE0LkI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -O https://mcauleylab.ucsd.edu/public_datasets/data/amazon_2023/raw/review_categories/All_Beauty.jsonl.gz\n",
        "!curl -O https://mcauleylab.ucsd.edu/public_datasets/data/amazon_2023/raw/meta_categories/meta_All_Beauty.jsonl.gz\n",
        "\n",
        "# !curl -O https://mcauleylab.ucsd.edu/public_datasets/data/amazon_2023/raw/review_categories/Beauty_and_Personal_Care.jsonl.gz\n",
        "# !curl -O https://mcauleylab.ucsd.edu/public_datasets/data/amazon_2023/raw/meta_categories/meta_Beauty_and_Personal_Care.jsonl.gz\n",
        "\n",
        "# !curl -O https://mcauleylab.ucsd.edu/public_datasets/data/amazon_2023/raw/review_categories/Health_and_Personal_Care.jsonl.gz\n",
        "# !curl -O https://mcauleylab.ucsd.edu/public_datasets/data/amazon_2023/raw/meta_categories/meta_Health_and_Personal_Care.jsonl.gz"
      ],
      "metadata": {
        "id": "qwZO9gut1pzE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50d054dc-a7aa-456d-ce1d-87009ff5d936"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 90.0M  100 90.0M    0     0  40.2M      0  0:00:02  0:00:02 --:--:-- 40.2M\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 38.0M  100 38.0M    0     0  29.7M      0  0:00:01  0:00:01 --:--:-- 29.7M\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gunzip All_Beauty.jsonl.gz\n",
        "# !gunzip Beauty_and_Personal_Care.jsonl.gz\n",
        "# !gunzip Health_and_Personal_Care.jsonl.gz\n",
        "!gunzip meta_All_Beauty.jsonl.gz\n",
        "# !gunzip meta_Beauty_and_Personal_Care.jsonl.gz\n",
        "# !gunzip meta_Health_and_Personal_Care.jsonl.gz"
      ],
      "metadata": {
        "id": "mIN4JVuBbBkM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install jsonlines pinecone openai azure-core -q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dQalPt5SX3uG",
        "outputId": "da58bbf6-c1ad-49de-a25b-ed276b8c704f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.6/47.6 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m745.9/745.9 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m214.0/214.0 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m280.9/280.9 kB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata"
      ],
      "metadata": {
        "id": "gLrcIOBmtVtd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "pprint = lambda x: print(json.dumps(x, indent=2)) if isinstance(x, dict) else display(x)"
      ],
      "metadata": {
        "id": "fXsS6dJvXd5B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import jsonlines\n",
        "\n",
        "def load_jsonl(file_path):\n",
        "\n",
        "  data_list = []\n",
        "\n",
        "  with jsonlines.open(file_path) as reader:\n",
        "      for obj in reader:\n",
        "          data_list.append(obj)\n",
        "  return data_list\n"
      ],
      "metadata": {
        "id": "Zp4s7nRpaew5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_beauty_reviews_raw = load_jsonl('All_Beauty.jsonl')"
      ],
      "metadata": {
        "id": "X2nLpTNua11K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_beauty_items_raw = load_jsonl('meta_All_Beauty.jsonl')"
      ],
      "metadata": {
        "id": "qvBddA85gWqa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Health_and_Personal_Care_reviews_raw = load_jsonl('Health_and_Personal_Care.jsonl')"
      ],
      "metadata": {
        "id": "NAF75XWyqDiZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Health_and_Personal_Care_items_raw = load_jsonl('meta_Health_and_Personal_Care.jsonl')"
      ],
      "metadata": {
        "id": "kS705QcFqH7h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Processing\n",
        "\n",
        "- Remove Irrelevant Keys\n",
        "\n",
        "JSON objects need to be converted to text before they can be embedded. We need to extract 2 types of information:\n",
        "- Semantic text (Names, descriptions etc). These will be used to generate embeddings.\n",
        "- Product ID, Price, main category, pricing. These will be inserted as metadata."
      ],
      "metadata": {
        "id": "6zIn2n96jSGn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def replace_empty_with_zero(data_list):\n",
        "    \"\"\"\n",
        "    Replaces empty/None values with 0 in a list of first-layer dictionaries.\n",
        "    \"\"\"\n",
        "    for item in data_list:\n",
        "        if isinstance(item, dict):\n",
        "            for key, value in item.items():\n",
        "                # Check for None or empty string values\n",
        "                if value is None or value == \"\":\n",
        "                    item[key] = 0\n",
        "                # You can add more conditions here (e.g., if value == [])\n",
        "    return data_list"
      ],
      "metadata": {
        "id": "a2D_TgVLvaf7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def remove_invalid_chars(text):\n",
        "    # This pattern keeps only alphanumeric characters and spaces\n",
        "    # You can customize the allowed characters within the square brackets\n",
        "    cleaned_text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
        "\n",
        "\n",
        "    # 2. Fix the \"34\" quote artifact (replace 34 followed by text with a quote)\n",
        "    # This regex looks for 34 surrounding words or sticking to them\n",
        "    cleaned_text = re.sub(r'34', '\"', cleaned_text)\n",
        "\n",
        "    # 3. Fix the \"br\" artifact (replace 'br' at end of words with a space)\n",
        "    cleaned_text = re.sub(r'br\\s+', ' ', cleaned_text) # Fix \"br \"\n",
        "    cleaned_text = re.sub(r'br(?=[A-Z])', ' ', cleaned_text) # Fix \"br\" before Capital letter (end of sentence)\n",
        "\n",
        "    # 4. Remove extra whitespace\n",
        "    cleaned_text = cleaned_text.strip()\n",
        "    return cleaned_text"
      ],
      "metadata": {
        "id": "_Gd0Gl44cTNk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_keys_items(data):\n",
        "\n",
        "  keys_to_extract = [\"main_category\", \"title\", \"parent_asin\", \"average_rating\", \"rating_number\", \"price\", \"store\"]\n",
        "\n",
        "  new_data = [\n",
        "      {key: value for key, value in item.items() if key in keys_to_extract}\n",
        "      for item in data\n",
        "  ]\n",
        "\n",
        "  return new_data"
      ],
      "metadata": {
        "id": "ti70pD1mgTD1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_keys_reviews(data):\n",
        "\n",
        "  keys_to_extract = [\"text\", \"rating\", \"parent_asin\", \"helpful_vote\", \"verified_purchase\"]\n",
        "\n",
        "  new_data = [\n",
        "      {key: value for key, value in item.items() if key in keys_to_extract}\n",
        "      for item in data\n",
        "  ]\n",
        "\n",
        "  return new_data"
      ],
      "metadata": {
        "id": "WD5BBKpZdOlv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def serialize_item(item):\n",
        "    # Parse details JSON if string, filter out UPC\n",
        "    details_dict = json.loads(item['details']) if isinstance(item['details'], str) else {}\n",
        "    valid_details = {k: v for k, v in details_dict.items() if \"UPC\" not in k}\n",
        "\n",
        "    # Construct rich text\n",
        "    text = f\"Product: {item['title']}\\n\"\n",
        "    text += f\"Category: {item['main_category']}\\n\"\n",
        "    text += f\"Features: {', '.join(item['features'])}\\n\"\n",
        "    text += f\"Description: {', '.join(item['description'])}\\n\"\n",
        "    text += f\"Details: {valid_details}\"\n",
        "\n",
        "    return text"
      ],
      "metadata": {
        "id": "07l-pyFioSCp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def serialize_review(review):\n",
        "    return f\"Title: {remove_invalid_chars(review['title'])}\\nReview: {remove_invalid_chars(review['text'])}\""
      ],
      "metadata": {
        "id": "7bob_0zmrpa0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# all_beauty_reviews_text = []\n",
        "# all_beauty_items_text =[]\n",
        "\n",
        "\n",
        "# for i in all_beauty_reviews_raw:\n",
        "#   all_beauty_reviews_text.append(serialize_review(i))\n",
        "\n",
        "\n",
        "# for j in all_beauty_items_raw:\n",
        "#   all_beauty_items_text.append(serialize_item(j))"
      ],
      "metadata": {
        "id": "0iKmUn4Urzx5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# all_beauty_reviews_meta = extract_keys_reviews(all_beauty_reviews_raw)\n",
        "# all_beauty_items_meta = extract_keys_items(all_beauty_items_raw)"
      ],
      "metadata": {
        "id": "YiYhLI3aUVmF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Filter out items for Sanity\n",
        "\n",
        "There are 112590 All Beauty Items.\n",
        "\n",
        "It takes 45 minutes to generate embeddings and the embedding file is around 600mb\n",
        "\n",
        "```\n",
        "Memory consumed by array elements (nbytes): 659.70703125 mb\n",
        "Memory consumed by the NumPy object (sys.getsizeof): 659.7071533203125 mb\n",
        "```\n",
        "\n",
        "For the purposes of this demo we will limit it to the first 5000 items."
      ],
      "metadata": {
        "id": "sWqOdulzqeGF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_beauty_items_raw_short = all_beauty_items_raw[:5000]"
      ],
      "metadata": {
        "id": "DH8ORf4_rXVO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unique_parent_asin = set([item['parent_asin'] for item in all_beauty_items_raw_short])"
      ],
      "metadata": {
        "id": "in1lXO26OUta"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_beauty_reviews_raw_short = [review for review in all_beauty_reviews_raw if review['parent_asin'] in unique_parent_asin]"
      ],
      "metadata": {
        "id": "q8vCn5FoR_1a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#remove empty reviews to prevent errors\n",
        "all_beauty_reviews_raw_short = [review for review in all_beauty_reviews_raw_short if review['text'] and review['text'].strip() and review['title'] and review['title'].strip()]"
      ],
      "metadata": {
        "id": "OwhLJiOgiXev"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(all_beauty_reviews_raw_short)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RV1TXpcfSHsk",
        "outputId": "2a065960-1fc4-493b-932d-579315f56391"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "40348"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_beauty_reviews_text = []\n",
        "all_beauty_items_text =[]\n",
        "\n",
        "# limit to 600 characters per review to prevent overload\n",
        "for i in all_beauty_reviews_raw_short:\n",
        "  all_beauty_reviews_text.append(serialize_review(i)[:600])\n",
        "\n",
        "\n",
        "for j in all_beauty_items_raw_short:\n",
        "  all_beauty_items_text.append(serialize_item(j))"
      ],
      "metadata": {
        "id": "LUHqpPBFZpL-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_beauty_reviews_meta = extract_keys_reviews(all_beauty_reviews_raw_short)\n",
        "all_beauty_items_meta = extract_keys_items(all_beauty_items_raw_short)"
      ],
      "metadata": {
        "id": "mSIirGyXZsyQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_beauty_items_meta = replace_empty_with_zero(all_beauty_items_meta)\n",
        "all_beauty_reviews_meta = replace_empty_with_zero(all_beauty_reviews_meta)"
      ],
      "metadata": {
        "id": "1ZGG2aYTvgtQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate Embeddings"
      ],
      "metadata": {
        "id": "8StUZFU9sYVW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from openai import AzureOpenAI\n",
        "\n",
        "\n",
        "endpoint = \"https://openai-gdig.cognitiveservices.azure.com/\"\n",
        "model_name = \"text-embedding-3-small\"\n",
        "deployment = \"text-embedding-3-small\"\n",
        "\n",
        "\n",
        "api_version = \"2024-02-01\"\n",
        "\n",
        "\n",
        "client = AzureOpenAI(\n",
        "    api_version=\"2024-12-01-preview\",\n",
        "    azure_endpoint=endpoint,\n",
        "    api_key=userdata.get('azure_openai')\n",
        ")\n",
        "\n",
        "\n",
        "# response = client.embeddings.create(\n",
        "#     input=[\"first phrase\",\"second phrase\",\"third phrase\"],\n",
        "#     model=deployment\n",
        "# )\n",
        "\n",
        "\n",
        "# for item in response.data:\n",
        "#     length = len(item.embedding)\n",
        "#     print(\n",
        "#         f\"data[{item.index}]: length={length}, \"\n",
        "#         f\"[{item.embedding[0]}, {item.embedding[1]}, \"\n",
        "#         f\"..., {item.embedding[length-2]}, {item.embedding[length-1]}]\"\n",
        "#     )\n",
        "# print(response.usage)"
      ],
      "metadata": {
        "id": "I3f200PYsW4N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We need to modify the code to avoid hitting rate limits. Alternatively, increase our quota on Azure"
      ],
      "metadata": {
        "id": "KchTQYtTW4PE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "afHPnRXYZHGQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "batch_size = 256                # tune this to be under rate limits\n",
        "delay = 2.5                    # seconds to wait between calls\n",
        "\n",
        "item_embeddings = []\n",
        "\n",
        "for i in tqdm(range(0, len(all_beauty_items_text), batch_size)):\n",
        "    batch = all_beauty_items_text[i : i + batch_size]\n",
        "\n",
        "    response = client.embeddings.create(\n",
        "        model=deployment,\n",
        "        input=batch\n",
        "    )\n",
        "\n",
        "    item_embeddings.extend(response.data)\n",
        "\n",
        "    # wait before the next batch\n",
        "    time.sleep(delay)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZutllF_sW_8c",
        "outputId": "8e9b0194-01b9-4cee-8a82-6a8922c097aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [01:55<00:00,  5.80s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "batch_size = 128                # tune this to be under rate limits\n",
        "delay = 2.5                    # seconds to wait between calls\n",
        "\n",
        "review_embeddings = []\n",
        "\n",
        "for i in tqdm(range(0, len(all_beauty_reviews_text), batch_size)):\n",
        "    batch = all_beauty_reviews_text[i : i + batch_size]\n",
        "\n",
        "    try:\n",
        "      response = client.embeddings.create(\n",
        "          model=deployment,\n",
        "          input=batch\n",
        "      )\n",
        "\n",
        "    except Exception as e:\n",
        "      print(f\"Error occurred with input: {batch}\")\n",
        "      print(f\"Error details: {e}\")\n",
        "\n",
        "\n",
        "    review_embeddings.extend(response.data)\n",
        "\n",
        "    # wait before the next batch\n",
        "    time.sleep(delay)\n"
      ],
      "metadata": {
        "id": "YhPlr8nnYvcE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77b60f92-a432-4f98-8c56-c28c9e4f976b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 316/316 [20:22<00:00,  3.87s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "item_embeddings = [item.embedding for item in item_embeddings]\n",
        "review_embeddings = [item.embedding for item in review_embeddings]"
      ],
      "metadata": {
        "id": "X2giaLOjoXNZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import numpy as np\n",
        "\n",
        "# Convert the list to a NumPy array for efficient memory calculation\n",
        "embeddings_np = np.array(item_embeddings, dtype=np.float32)\n",
        "# np.save('item_embeddings.npy', embeddings_np)\n",
        "\n",
        "# Get the number of bytes consumed by the elements of the array\n",
        "memory_bytes_nbytes = embeddings_np.nbytes\n",
        "megabyte_value = memory_bytes_nbytes / (1024 * 1024)\n",
        "print(f\"Memory consumed by array elements (nbytes): {megabyte_value} mb\")\n",
        "\n",
        "# Use sys.getsizeof for a more complete but less precise measure of the entire object\n",
        "# This includes Python overhead, but may not recursively count all referenced objects\n",
        "memory_bytes_sys = sys.getsizeof(embeddings_np)\n",
        "megabyte_value_sys = memory_bytes_sys / (1024 * 1024)\n",
        "print(f\"Memory consumed by the NumPy object (sys.getsizeof): {megabyte_value_sys} mb\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kJe5UYt_kjBA",
        "outputId": "e5ddf6b9-6c97-4fa6-ce63-e1c4c6b94e6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Memory consumed by array elements (nbytes): 29.296875 mb\n",
            "Memory consumed by the NumPy object (sys.getsizeof): 29.2969970703125 mb\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check for Duplicate parent_asin for products"
      ],
      "metadata": {
        "id": "ypA7lUOumfro"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "def has_duplicates_by_key(data_list, key_name):\n",
        "    \"\"\"\n",
        "    Checks if a specific key has duplicate values in a list of dictionaries.\n",
        "\n",
        "    Args:\n",
        "        data_list (list): The list of dictionaries (from JSON data).\n",
        "        key_name (str): The key to check for duplicate values.\n",
        "\n",
        "    Returns:\n",
        "        bool: True if duplicates exist for the key, False otherwise.\n",
        "    \"\"\"\n",
        "    # Extract all values for the specified key into a new list\n",
        "    key_values = [item[key_name] for item in data_list if key_name in item]\n",
        "\n",
        "    # Compare the length of the list with the length of a set (which removes duplicates)\n",
        "    return len(key_values) != len(set(key_values))"
      ],
      "metadata": {
        "id": "dz366gSUklkh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if has_duplicates_by_key(all_beauty_items_meta, 'parent_asin'):\n",
        "    print(\"Duplicate IDs found.\")\n",
        "else:\n",
        "    print(\"No duplicate IDs.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6em-1SFClm8I",
        "outputId": "f454cb99-ce13-4863-c4c7-79bb8131c646"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No duplicate IDs.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Upsert Embeddings into Pinecone with Metadata"
      ],
      "metadata": {
        "id": "TaDMMH04sbRK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_vector_objects(vectors, json_objects):\n",
        "    \"\"\"\n",
        "    Constructs a list of dicts with id, vector values, and metadata.\n",
        "\n",
        "    vectors: List of lists (vectors)\n",
        "    json_objects: List of dicts (metadata)\n",
        "\n",
        "    Both lists must be the same length and aligned.\n",
        "    \"\"\"\n",
        "    result = []\n",
        "    for vector, obj in zip(vectors, json_objects):\n",
        "        item = {\n",
        "            \"id\": obj[\"parent_asin\"],       # id from parent_asin\n",
        "            \"values\": vector,               # vector values\n",
        "            \"metadata\": obj                 # entire json object as metadata\n",
        "        }\n",
        "        result.append(item)\n",
        "    return result\n"
      ],
      "metadata": {
        "id": "jpRg1eB1jEQG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_vector_reviews(vectors, json_objects):\n",
        "    \"\"\"\n",
        "    Constructs a list of dicts with id, vector values, and metadata.\n",
        "\n",
        "    vectors: List of lists (vectors)\n",
        "    json_objects: List of dicts (metadata)\n",
        "\n",
        "    Both lists must be the same length and aligned.\n",
        "    \"\"\"\n",
        "    result = []\n",
        "    count = 0\n",
        "    for vector, obj in zip(vectors, json_objects):\n",
        "        count += 1\n",
        "        item = {\n",
        "            \"id\": str(count),      # id from parent_asin\n",
        "            \"values\": vector,               # vector values\n",
        "            \"metadata\": obj                 # entire json object as metadata\n",
        "        }\n",
        "        result.append(item)\n",
        "    return result\n"
      ],
      "metadata": {
        "id": "MJ0F3B6LtYEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "item_vectors = build_vector_objects(item_embeddings, all_beauty_items_meta)"
      ],
      "metadata": {
        "id": "4fgSeU0unqrG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "review_vectors = build_vector_reviews(review_embeddings, all_beauty_reviews_meta)"
      ],
      "metadata": {
        "id": "EYZZwMD-tX0C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pinecone import Pinecone\n",
        "import itertools\n",
        "\n",
        "# Initialize Pinecone client\n",
        "pc = Pinecone(api_key=userdata.get('pinecone'))\n",
        "index_name = \"amazon-beauty-items\"\n",
        "index = pc.Index(index_name)\n",
        "\n",
        "# Helper function to break a list into smaller chunks\n",
        "def chunks(iterable, batch_size=100):\n",
        "    it = iter(iterable)\n",
        "    chunk = list(itertools.islice(it, batch_size))\n",
        "    while chunk:\n",
        "        yield chunk\n",
        "        chunk = list(itertools.islice(it, batch_size))\n",
        "\n",
        "# Upsert the vectors in batches of 100\n",
        "# (You can try 200 if your metadata is very small)\n",
        "for ids_vectors_chunk in chunks(item_vectors, batch_size=100):\n",
        "    index.upsert(vectors=ids_vectors_chunk)\n",
        "\n",
        "# Check index stats after upsert\n",
        "print(\"Upsert complete.\")\n",
        "print(index.describe_index_stats())"
      ],
      "metadata": {
        "id": "-9BHrQgTseRg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9371539-28c1-43ca-cd2f-c7016258491c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Upsert complete.\n",
            "{'_response_info': {'raw_headers': {'connection': 'keep-alive',\n",
            "                                    'content-length': '188',\n",
            "                                    'content-type': 'application/json',\n",
            "                                    'date': 'Fri, 09 Jan 2026 17:13:08 GMT',\n",
            "                                    'grpc-status': '0',\n",
            "                                    'server': 'envoy',\n",
            "                                    'x-envoy-upstream-service-time': '40',\n",
            "                                    'x-pinecone-request-id': '3889210117587860160',\n",
            "                                    'x-pinecone-request-latency-ms': '39',\n",
            "                                    'x-pinecone-response-duration-ms': '41'}},\n",
            " 'dimension': 1536,\n",
            " 'index_fullness': 0.0,\n",
            " 'memoryFullness': 0.0,\n",
            " 'metric': 'cosine',\n",
            " 'namespaces': {'__default__': {'vector_count': 5000}},\n",
            " 'storageFullness': 0.0,\n",
            " 'total_vector_count': 5000,\n",
            " 'vector_type': 'dense'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pinecone import Pinecone\n",
        "import itertools\n",
        "\n",
        "# Initialize Pinecone client\n",
        "pc = Pinecone(api_key=userdata.get('pinecone'))\n",
        "index_name = \"amazon-beauty-reviews\"\n",
        "index = pc.Index(index_name)\n",
        "\n",
        "# Helper function to break a list into smaller chunks\n",
        "def chunks(iterable, batch_size=100):\n",
        "    it = iter(iterable)\n",
        "    chunk = list(itertools.islice(it, batch_size))\n",
        "    while chunk:\n",
        "        yield chunk\n",
        "        chunk = list(itertools.islice(it, batch_size))\n",
        "\n",
        "# Upsert the vectors in batches of 100\n",
        "# (You can try 200 if your metadata is very small)\n",
        "for ids_vectors_chunk in chunks(review_vectors, batch_size=100):\n",
        "    index.upsert(vectors=ids_vectors_chunk)\n",
        "\n",
        "# Check index stats after upsert\n",
        "print(\"Upsert complete.\")\n",
        "print(index.describe_index_stats())"
      ],
      "metadata": {
        "id": "mbsjijnrZZkC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb5c4b7c-73be-49f2-afa0-f23300c9d94c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Upsert complete.\n",
            "{'_response_info': {'raw_headers': {'connection': 'keep-alive',\n",
            "                                    'content-length': '190',\n",
            "                                    'content-type': 'application/json',\n",
            "                                    'date': 'Fri, 09 Jan 2026 17:36:09 GMT',\n",
            "                                    'grpc-status': '0',\n",
            "                                    'server': 'envoy',\n",
            "                                    'x-envoy-upstream-service-time': '42',\n",
            "                                    'x-pinecone-request-id': '1937050039581043016',\n",
            "                                    'x-pinecone-request-latency-ms': '41',\n",
            "                                    'x-pinecone-response-duration-ms': '43'}},\n",
            " 'dimension': 1536,\n",
            " 'index_fullness': 0.0,\n",
            " 'memoryFullness': 0.0,\n",
            " 'metric': 'cosine',\n",
            " 'namespaces': {'__default__': {'vector_count': 40348}},\n",
            " 'storageFullness': 0.0,\n",
            " 'total_vector_count': 40348,\n",
            " 'vector_type': 'dense'}\n"
          ]
        }
      ]
    }
  ]
}